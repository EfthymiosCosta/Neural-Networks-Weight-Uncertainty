{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bayes_by_Backprop_NN_400_layers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNVsDqQcV3HVsNUiq30GKng",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EfthymiosCosta/Neural-Networks-Weight-Uncertainty/blob/main/Bayes_by_Backprop_NN_400_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_ArF06Ajx0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c94ce207-7aae-4ba1-a4e9-3e75234e1450"
      },
      "source": [
        "!git clone https://github.com/kumar-shridhar/PyTorch-BayesianCNN.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Total 1687 (delta 71), reused 88 (delta 46), pack-reused 1561\u001b[K\n",
            "Receiving objects: 100% (1687/1687), 67.83 MiB | 3.16 MiB/s, done.\n",
            "Resolving deltas: 100% (1007/1007), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd-C-EuPk8L2",
        "outputId": "923a17e2-8ec9-4065-802f-fa9a23ad4abd"
      },
      "source": [
        "%cd \"PyTorch-BayesianCNN\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PyTorch-BayesianCNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ycosHgyj9NL"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import data\n",
        "import utils\n",
        "import metrics\n",
        "import config_bayesian as cfg\n",
        "from models.BayesianModels.Bayesian3Conv3FC import BBB3Conv3FC\n",
        "from models.BayesianModels.BayesianAlexNet import BBBAlexNet\n",
        "from models.BayesianModels.BayesianLeNet import BBBLeNet"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrvqPzTHZE6_"
      },
      "source": [
        "import math\n",
        "import torch.nn as nn\n",
        "from layers import BBB_Linear, BBB_Conv2d\n",
        "from layers import BBB_LRT_Linear, BBB_LRT_Conv2d\n",
        "from layers import FlattenLayer, ModuleWrapper\n",
        "\n",
        "\n",
        "class Net(ModuleWrapper):\n",
        "    '''The architecture of LeNet with Bayesian Layers'''\n",
        "\n",
        "    def __init__(self, outputs, inputs, priors, layer_type='lrt', activation_type='softplus'):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.num_classes = outputs\n",
        "        self.layer_type = layer_type\n",
        "        self.priors = priors\n",
        "\n",
        "        BBBLinear = BBB_Linear\n",
        "        self.act = nn.ReLU\n",
        "\n",
        "        self.flatten = FlattenLayer(1024)\n",
        "        self.fc1 = BBBLinear(1024, 400, bias=True, priors=self.priors)\n",
        "        self.act1 = self.act()\n",
        "\n",
        "        self.fc2 = BBBLinear(400, 400, bias=True, priors=self.priors)\n",
        "        self.act2 = self.act()\n",
        "\n",
        "        self.fc3 = BBBLinear(400, outputs, bias=True, priors=self.priors)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1MStMDzkQFK"
      },
      "source": [
        "# CUDA settings\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def getModel(net_type, inputs, outputs, priors, layer_type, activation_type):\n",
        "    return Net(outputs, inputs, priors, layer_type, activation_type)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9quPfIOkRx3"
      },
      "source": [
        "def train_model(net, optimizer, criterion, trainloader, num_ens=1, beta_type=0.1, epoch=None, num_epochs=None):\n",
        "    net.train()\n",
        "    training_loss = 0.0\n",
        "    accs = []\n",
        "    kl_list = []\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 1):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = torch.zeros(inputs.shape[0], net.num_classes, num_ens).to(device)\n",
        "\n",
        "        kl = 0.0\n",
        "        for j in range(num_ens):\n",
        "            net_out, _kl = net(inputs)\n",
        "            kl += _kl\n",
        "            outputs[:, :, j] = F.log_softmax(net_out, dim=1)\n",
        "        \n",
        "        kl = kl / num_ens\n",
        "        kl_list.append(kl.item())\n",
        "        log_outputs = utils.logmeanexp(outputs, dim=2)\n",
        "\n",
        "        beta = metrics.get_beta(i-1, len(trainloader), beta_type, epoch, num_epochs)\n",
        "        loss = criterion(log_outputs, labels, kl, beta)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        accs.append(metrics.acc(log_outputs.data, labels))\n",
        "        training_loss += loss.cpu().data.numpy()\n",
        "    return training_loss/len(trainloader), np.mean(accs), np.mean(kl_list)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_gx6CPNlBhP"
      },
      "source": [
        "def validate_model(net, criterion, validloader, num_ens=1, beta_type=0.1, epoch=None, num_epochs=None):\n",
        "    \"\"\"Calculate ensemble accuracy and NLL Loss\"\"\"\n",
        "    net.train()\n",
        "    valid_loss = 0.0\n",
        "    accs = []\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(validloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = torch.zeros(inputs.shape[0], net.num_classes, num_ens).to(device)\n",
        "        kl = 0.0\n",
        "        for j in range(num_ens):\n",
        "            net_out, _kl = net(inputs)\n",
        "            kl += _kl\n",
        "            outputs[:, :, j] = F.log_softmax(net_out, dim=1).data\n",
        "\n",
        "        log_outputs = utils.logmeanexp(outputs, dim=2)\n",
        "\n",
        "        beta = metrics.get_beta(i-1, len(validloader), beta_type, epoch, num_epochs)\n",
        "        valid_loss += criterion(log_outputs, labels, kl, beta).item()\n",
        "        accs.append(metrics.acc(log_outputs, labels))\n",
        "\n",
        "    return valid_loss/len(validloader), np.mean(accs)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrV_NMSQ0gqv"
      },
      "source": [
        "def getDataloader(trainset, testset, batch_size, num_workers):\n",
        "    num_train = len(trainset)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle = True, num_workers=num_workers)\n",
        "    test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, \n",
        "        num_workers=num_workers)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sFELH0klGsg"
      },
      "source": [
        "def run(dataset, net_type):\n",
        "\n",
        "    ELBO = []\n",
        "    train_acc_tracker = []\n",
        "    val_acc_tracker = []\n",
        "    # Hyper Parameter settings\n",
        "    layer_type = cfg.layer_type\n",
        "    activation_type = cfg.activation_type\n",
        "    priors = cfg.priors\n",
        "\n",
        "    train_ens = cfg.train_ens\n",
        "    valid_ens = cfg.valid_ens\n",
        "    n_epochs = 200\n",
        "    lr_start = cfg.lr_start\n",
        "    # set to 0 cos otherwise sometimes get assertion error: can only test a child process\n",
        "    num_workers = 2\n",
        "    valid_size = 0.001\n",
        "    batch_size = cfg.batch_size\n",
        "    beta_type = cfg.beta_type\n",
        "\n",
        "    trainset, testset, inputs, outputs = data.getDataset(dataset)\n",
        "    train_loader, test_loader = getDataloader(\n",
        "        trainset, testset, batch_size, num_workers)\n",
        "    net = getModel(net_type, inputs, outputs, priors, layer_type, activation_type).to(device)\n",
        "\n",
        "    ckpt_dir = f'checkpoints/{dataset}/bayesian'\n",
        "    ckpt_name = f'checkpoints/{dataset}/bayesian/model_{net_type}_{layer_type}_{activation_type}.pt'\n",
        "\n",
        "    if not os.path.exists(ckpt_dir):\n",
        "        os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "    criterion = metrics.ELBO(len(trainset)).to(device)\n",
        "    optimizer = Adam(net.parameters(), lr=lr_start)\n",
        "    lr_sched = lr_scheduler.ReduceLROnPlateau(optimizer, patience=6, verbose=True)\n",
        "    valid_loss_max = np.Inf\n",
        "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        train_loss, train_acc, train_kl = train_model(net, optimizer, criterion, train_loader, num_ens=train_ens, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)\n",
        "        # changed valid LOSS TO TEST LOSS!!!\n",
        "        valid_loss, valid_acc = validate_model(net, criterion, test_loader, num_ens=valid_ens, beta_type=beta_type, epoch=epoch, num_epochs=n_epochs)\n",
        "        lr_sched.step(valid_loss)\n",
        "\n",
        "        ELBO += [train_loss]\n",
        "        train_acc_tracker += [train_acc]\n",
        "        val_acc_tracker += [valid_acc]\n",
        "\n",
        "        print('Epoch: {} \\tTraining Loss: {:.4f} \\tTraining Accuracy: {:.4f} \\tValidation Loss: {:.4f} \\tValidation Accuracy: {:.4f} \\ttrain_kl_div: {:.4f}'.format(\n",
        "            epoch, train_loss, train_acc, valid_loss, valid_acc, train_kl))\n",
        "\n",
        "        # save model if validation accuracy has increased\n",
        "        if valid_loss <= valid_loss_max:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "                valid_loss_max, valid_loss))\n",
        "            torch.save(net.state_dict(), ckpt_name)\n",
        "            valid_loss_max = valid_loss\n",
        "    return net, ELBO, train_acc_tracker, val_acc_tracker"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC-oRSNXlSHp"
      },
      "source": [
        "dataset = 'MNIST'\n",
        "net_type = 'Net'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGtvSnbVlWic",
        "outputId": "520ccc5f-f6f0-4c2a-dbe4-53f61e479666"
      },
      "source": [
        "net, ELBO, train_acc, test_acc = run(dataset, net_type)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 \tTraining Loss: 7001218.3787 \tTraining Accuracy: 0.8759 \tValidation Loss: 4548794.0250 \tValidation Accuracy: 0.9113 \ttrain_kl_div: 69730427.8468\n",
            "Validation loss decreased (inf --> 4548794.025000).  Saving model ...\n",
            "Epoch: 1 \tTraining Loss: 3779287.3064 \tTraining Accuracy: 0.9097 \tValidation Loss: 3176680.0312 \tValidation Accuracy: 0.9147 \ttrain_kl_div: 37576121.0723\n",
            "Validation loss decreased (4548794.025000 --> 3176680.031250).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 2758580.1436 \tTraining Accuracy: 0.9178 \tValidation Loss: 2389482.8125 \tValidation Accuracy: 0.9280 \ttrain_kl_div: 27394662.3149\n",
            "Validation loss decreased (3176680.031250 --> 2389482.812500).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 2108256.2617 \tTraining Accuracy: 0.9272 \tValidation Loss: 1852714.9406 \tValidation Accuracy: 0.9377 \ttrain_kl_div: 20914604.0681\n",
            "Validation loss decreased (2389482.812500 --> 1852714.940625).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 1652309.9021 \tTraining Accuracy: 0.9317 \tValidation Loss: 1468591.2656 \tValidation Accuracy: 0.9395 \ttrain_kl_div: 16373456.1362\n",
            "Validation loss decreased (1852714.940625 --> 1468591.265625).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 1319008.2553 \tTraining Accuracy: 0.9404 \tValidation Loss: 1181072.9187 \tValidation Accuracy: 0.9475 \ttrain_kl_div: 13059853.5830\n",
            "Validation loss decreased (1468591.265625 --> 1181072.918750).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 1068807.1122 \tTraining Accuracy: 0.9462 \tValidation Loss: 963266.5781 \tValidation Accuracy: 0.9523 \ttrain_kl_div: 10571328.0596\n",
            "Validation loss decreased (1181072.918750 --> 963266.578125).  Saving model ...\n",
            "Epoch: 7 \tTraining Loss: 876776.3136 \tTraining Accuracy: 0.9490 \tValidation Loss: 794278.7063 \tValidation Accuracy: 0.9521 \ttrain_kl_div: 8658841.4064\n",
            "Validation loss decreased (963266.578125 --> 794278.706250).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 725734.6481 \tTraining Accuracy: 0.9539 \tValidation Loss: 660317.9922 \tValidation Accuracy: 0.9592 \ttrain_kl_div: 7158708.0106\n",
            "Validation loss decreased (794278.706250 --> 660317.992188).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 605459.3793 \tTraining Accuracy: 0.9569 \tValidation Loss: 553143.8469 \tValidation Accuracy: 0.9573 \ttrain_kl_div: 5963582.0766\n",
            "Validation loss decreased (660317.992188 --> 553143.846875).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 508517.3866 \tTraining Accuracy: 0.9576 \tValidation Loss: 465946.8000 \tValidation Accuracy: 0.9587 \ttrain_kl_div: 4999700.0660\n",
            "Validation loss decreased (553143.846875 --> 465946.800000).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 428914.1188 \tTraining Accuracy: 0.9614 \tValidation Loss: 393791.4422 \tValidation Accuracy: 0.9622 \ttrain_kl_div: 4210816.7660\n",
            "Validation loss decreased (465946.800000 --> 393791.442188).  Saving model ...\n",
            "Epoch: 12 \tTraining Loss: 363538.0426 \tTraining Accuracy: 0.9636 \tValidation Loss: 334318.7539 \tValidation Accuracy: 0.9676 \ttrain_kl_div: 3561114.3894\n",
            "Validation loss decreased (393791.442188 --> 334318.753906).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 309358.5979 \tTraining Accuracy: 0.9635 \tValidation Loss: 284448.1594 \tValidation Accuracy: 0.9708 \ttrain_kl_div: 3021491.3447\n",
            "Validation loss decreased (334318.753906 --> 284448.159375).  Saving model ...\n",
            "Epoch: 14 \tTraining Loss: 263667.4688 \tTraining Accuracy: 0.9664 \tValidation Loss: 243168.4191 \tValidation Accuracy: 0.9696 \ttrain_kl_div: 2569749.6383\n",
            "Validation loss decreased (284448.159375 --> 243168.419141).  Saving model ...\n",
            "Epoch: 15 \tTraining Loss: 225514.4267 \tTraining Accuracy: 0.9672 \tValidation Loss: 208455.7898 \tValidation Accuracy: 0.9668 \ttrain_kl_div: 2189717.4394\n",
            "Validation loss decreased (243168.419141 --> 208455.789844).  Saving model ...\n",
            "Epoch: 16 \tTraining Loss: 193397.9398 \tTraining Accuracy: 0.9673 \tValidation Loss: 178348.5070 \tValidation Accuracy: 0.9699 \ttrain_kl_div: 1869090.7819\n",
            "Validation loss decreased (208455.789844 --> 178348.507031).  Saving model ...\n",
            "Epoch: 17 \tTraining Loss: 165828.1811 \tTraining Accuracy: 0.9687 \tValidation Loss: 153731.9562 \tValidation Accuracy: 0.9676 \ttrain_kl_div: 1596784.6989\n",
            "Validation loss decreased (178348.507031 --> 153731.956250).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 142638.0432 \tTraining Accuracy: 0.9688 \tValidation Loss: 132400.2205 \tValidation Accuracy: 0.9669 \ttrain_kl_div: 1365279.8362\n",
            "Validation loss decreased (153731.956250 --> 132400.220508).  Saving model ...\n",
            "Epoch: 19 \tTraining Loss: 122816.4823 \tTraining Accuracy: 0.9691 \tValidation Loss: 114086.4697 \tValidation Accuracy: 0.9658 \ttrain_kl_div: 1168518.6633\n",
            "Validation loss decreased (132400.220508 --> 114086.469727).  Saving model ...\n",
            "Epoch: 20 \tTraining Loss: 105648.3883 \tTraining Accuracy: 0.9713 \tValidation Loss: 98316.9236 \tValidation Accuracy: 0.9686 \ttrain_kl_div: 999799.4652\n",
            "Validation loss decreased (114086.469727 --> 98316.923633).  Saving model ...\n",
            "Epoch: 21 \tTraining Loss: 91168.8567 \tTraining Accuracy: 0.9707 \tValidation Loss: 85360.1021 \tValidation Accuracy: 0.9662 \ttrain_kl_div: 855459.4532\n",
            "Validation loss decreased (98316.923633 --> 85360.102148).  Saving model ...\n",
            "Epoch: 22 \tTraining Loss: 78732.1578 \tTraining Accuracy: 0.9716 \tValidation Loss: 73562.5754 \tValidation Accuracy: 0.9702 \ttrain_kl_div: 732257.5154\n",
            "Validation loss decreased (85360.102148 --> 73562.575391).  Saving model ...\n",
            "Epoch: 23 \tTraining Loss: 68278.3632 \tTraining Accuracy: 0.9706 \tValidation Loss: 63657.1666 \tValidation Accuracy: 0.9688 \ttrain_kl_div: 627328.7912\n",
            "Validation loss decreased (73562.575391 --> 63657.166602).  Saving model ...\n",
            "Epoch: 24 \tTraining Loss: 59106.5874 \tTraining Accuracy: 0.9720 \tValidation Loss: 55544.1745 \tValidation Accuracy: 0.9693 \ttrain_kl_div: 537699.9424\n",
            "Validation loss decreased (63657.166602 --> 55544.174512).  Saving model ...\n",
            "Epoch: 25 \tTraining Loss: 51207.0122 \tTraining Accuracy: 0.9729 \tValidation Loss: 48932.4547 \tValidation Accuracy: 0.9663 \ttrain_kl_div: 460959.9138\n",
            "Validation loss decreased (55544.174512 --> 48932.454688).  Saving model ...\n",
            "Epoch: 26 \tTraining Loss: 44732.4039 \tTraining Accuracy: 0.9733 \tValidation Loss: 42130.9641 \tValidation Accuracy: 0.9712 \ttrain_kl_div: 395684.1645\n",
            "Validation loss decreased (48932.454688 --> 42130.964063).  Saving model ...\n",
            "Epoch: 27 \tTraining Loss: 39083.2092 \tTraining Accuracy: 0.9734 \tValidation Loss: 37589.6256 \tValidation Accuracy: 0.9693 \ttrain_kl_div: 340334.6436\n",
            "Validation loss decreased (42130.964063 --> 37589.625586).  Saving model ...\n",
            "Epoch: 28 \tTraining Loss: 34288.3737 \tTraining Accuracy: 0.9745 \tValidation Loss: 32954.1016 \tValidation Accuracy: 0.9710 \ttrain_kl_div: 293565.6842\n",
            "Validation loss decreased (37589.625586 --> 32954.101611).  Saving model ...\n",
            "Epoch: 29 \tTraining Loss: 30205.8613 \tTraining Accuracy: 0.9744 \tValidation Loss: 29400.1268 \tValidation Accuracy: 0.9712 \ttrain_kl_div: 253834.9375\n",
            "Validation loss decreased (32954.101611 --> 29400.126807).  Saving model ...\n",
            "Epoch: 30 \tTraining Loss: 26977.6642 \tTraining Accuracy: 0.9738 \tValidation Loss: 26184.1145 \tValidation Accuracy: 0.9710 \ttrain_kl_div: 220437.4763\n",
            "Validation loss decreased (29400.126807 --> 26184.114502).  Saving model ...\n",
            "Epoch: 31 \tTraining Loss: 24199.6610 \tTraining Accuracy: 0.9743 \tValidation Loss: 23610.2418 \tValidation Accuracy: 0.9736 \ttrain_kl_div: 193088.5679\n",
            "Validation loss decreased (26184.114502 --> 23610.241846).  Saving model ...\n",
            "Epoch: 32 \tTraining Loss: 21506.4417 \tTraining Accuracy: 0.9757 \tValidation Loss: 21679.3772 \tValidation Accuracy: 0.9712 \ttrain_kl_div: 169502.6897\n",
            "Validation loss decreased (23610.241846 --> 21679.377222).  Saving model ...\n",
            "Epoch: 33 \tTraining Loss: 19910.9661 \tTraining Accuracy: 0.9746 \tValidation Loss: 19961.7421 \tValidation Accuracy: 0.9730 \ttrain_kl_div: 150473.1214\n",
            "Validation loss decreased (21679.377222 --> 19961.742114).  Saving model ...\n",
            "Epoch: 34 \tTraining Loss: 18045.2136 \tTraining Accuracy: 0.9752 \tValidation Loss: 18739.0223 \tValidation Accuracy: 0.9692 \ttrain_kl_div: 134108.9415\n",
            "Validation loss decreased (19961.742114 --> 18739.022314).  Saving model ...\n",
            "Epoch: 35 \tTraining Loss: 16674.2936 \tTraining Accuracy: 0.9762 \tValidation Loss: 17183.2697 \tValidation Accuracy: 0.9708 \ttrain_kl_div: 121065.7397\n",
            "Validation loss decreased (18739.022314 --> 17183.269678).  Saving model ...\n",
            "Epoch: 36 \tTraining Loss: 15463.8126 \tTraining Accuracy: 0.9759 \tValidation Loss: 16368.2329 \tValidation Accuracy: 0.9727 \ttrain_kl_div: 109776.4023\n",
            "Validation loss decreased (17183.269678 --> 16368.232910).  Saving model ...\n",
            "Epoch: 37 \tTraining Loss: 14707.9526 \tTraining Accuracy: 0.9752 \tValidation Loss: 15257.3147 \tValidation Accuracy: 0.9718 \ttrain_kl_div: 100695.6220\n",
            "Validation loss decreased (16368.232910 --> 15257.314722).  Saving model ...\n",
            "Epoch: 38 \tTraining Loss: 13892.1386 \tTraining Accuracy: 0.9755 \tValidation Loss: 14440.9238 \tValidation Accuracy: 0.9703 \ttrain_kl_div: 93121.6346\n",
            "Validation loss decreased (15257.314722 --> 14440.923755).  Saving model ...\n",
            "Epoch: 39 \tTraining Loss: 13244.7073 \tTraining Accuracy: 0.9764 \tValidation Loss: 13965.8085 \tValidation Accuracy: 0.9717 \ttrain_kl_div: 87197.3577\n",
            "Validation loss decreased (14440.923755 --> 13965.808521).  Saving model ...\n",
            "Epoch: 40 \tTraining Loss: 12563.8063 \tTraining Accuracy: 0.9768 \tValidation Loss: 13427.1091 \tValidation Accuracy: 0.9712 \ttrain_kl_div: 82028.7474\n",
            "Validation loss decreased (13965.808521 --> 13427.109131).  Saving model ...\n",
            "Epoch: 41 \tTraining Loss: 12213.3712 \tTraining Accuracy: 0.9767 \tValidation Loss: 12225.9676 \tValidation Accuracy: 0.9761 \ttrain_kl_div: 77481.2960\n",
            "Validation loss decreased (13427.109131 --> 12225.967615).  Saving model ...\n",
            "Epoch: 42 \tTraining Loss: 11726.3348 \tTraining Accuracy: 0.9769 \tValidation Loss: 13224.3691 \tValidation Accuracy: 0.9697 \ttrain_kl_div: 73954.1123\n",
            "Epoch: 43 \tTraining Loss: 11600.6599 \tTraining Accuracy: 0.9760 \tValidation Loss: 12429.1167 \tValidation Accuracy: 0.9729 \ttrain_kl_div: 71023.1466\n",
            "Epoch: 44 \tTraining Loss: 11135.0080 \tTraining Accuracy: 0.9765 \tValidation Loss: 12107.8225 \tValidation Accuracy: 0.9716 \ttrain_kl_div: 68463.7145\n",
            "Validation loss decreased (12225.967615 --> 12107.822498).  Saving model ...\n",
            "Epoch: 45 \tTraining Loss: 10867.0386 \tTraining Accuracy: 0.9785 \tValidation Loss: 11401.4464 \tValidation Accuracy: 0.9753 \ttrain_kl_div: 66333.0545\n",
            "Validation loss decreased (12107.822498 --> 11401.446375).  Saving model ...\n",
            "Epoch: 46 \tTraining Loss: 10498.4836 \tTraining Accuracy: 0.9776 \tValidation Loss: 11605.4336 \tValidation Accuracy: 0.9750 \ttrain_kl_div: 64165.8046\n",
            "Epoch: 47 \tTraining Loss: 10450.4118 \tTraining Accuracy: 0.9776 \tValidation Loss: 11491.9128 \tValidation Accuracy: 0.9743 \ttrain_kl_div: 62782.0867\n",
            "Epoch: 48 \tTraining Loss: 10385.4818 \tTraining Accuracy: 0.9769 \tValidation Loss: 11873.2536 \tValidation Accuracy: 0.9707 \ttrain_kl_div: 61356.0658\n",
            "Epoch: 49 \tTraining Loss: 10339.1130 \tTraining Accuracy: 0.9777 \tValidation Loss: 11093.7080 \tValidation Accuracy: 0.9750 \ttrain_kl_div: 60291.4803\n",
            "Validation loss decreased (11401.446375 --> 11093.707959).  Saving model ...\n",
            "Epoch: 50 \tTraining Loss: 9986.0399 \tTraining Accuracy: 0.9776 \tValidation Loss: 11037.1333 \tValidation Accuracy: 0.9758 \ttrain_kl_div: 58972.6452\n",
            "Validation loss decreased (11093.707959 --> 11037.133301).  Saving model ...\n",
            "Epoch: 51 \tTraining Loss: 9942.5647 \tTraining Accuracy: 0.9781 \tValidation Loss: 11823.2122 \tValidation Accuracy: 0.9688 \ttrain_kl_div: 58080.0397\n",
            "Epoch: 52 \tTraining Loss: 9696.8251 \tTraining Accuracy: 0.9783 \tValidation Loss: 10770.3968 \tValidation Accuracy: 0.9740 \ttrain_kl_div: 57055.5964\n",
            "Validation loss decreased (11037.133301 --> 10770.396814).  Saving model ...\n",
            "Epoch: 53 \tTraining Loss: 9708.0931 \tTraining Accuracy: 0.9780 \tValidation Loss: 11045.8831 \tValidation Accuracy: 0.9729 \ttrain_kl_div: 56131.4874\n",
            "Epoch: 54 \tTraining Loss: 9530.1356 \tTraining Accuracy: 0.9782 \tValidation Loss: 10928.6490 \tValidation Accuracy: 0.9724 \ttrain_kl_div: 55461.7738\n",
            "Epoch: 55 \tTraining Loss: 9404.9667 \tTraining Accuracy: 0.9788 \tValidation Loss: 10764.2484 \tValidation Accuracy: 0.9734 \ttrain_kl_div: 54623.2210\n",
            "Validation loss decreased (10770.396814 --> 10764.248450).  Saving model ...\n",
            "Epoch: 56 \tTraining Loss: 9411.4737 \tTraining Accuracy: 0.9786 \tValidation Loss: 10717.8006 \tValidation Accuracy: 0.9728 \ttrain_kl_div: 53998.8060\n",
            "Validation loss decreased (10764.248450 --> 10717.800610).  Saving model ...\n",
            "Epoch: 57 \tTraining Loss: 9153.3791 \tTraining Accuracy: 0.9802 \tValidation Loss: 10956.2265 \tValidation Accuracy: 0.9716 \ttrain_kl_div: 53278.5502\n",
            "Epoch: 58 \tTraining Loss: 9081.0145 \tTraining Accuracy: 0.9798 \tValidation Loss: 10837.7442 \tValidation Accuracy: 0.9729 \ttrain_kl_div: 52605.9405\n",
            "Epoch: 59 \tTraining Loss: 9183.0500 \tTraining Accuracy: 0.9792 \tValidation Loss: 10246.5100 \tValidation Accuracy: 0.9755 \ttrain_kl_div: 52043.8950\n",
            "Validation loss decreased (10717.800610 --> 10246.509973).  Saving model ...\n",
            "Epoch: 60 \tTraining Loss: 9023.4588 \tTraining Accuracy: 0.9795 \tValidation Loss: 10210.9132 \tValidation Accuracy: 0.9758 \ttrain_kl_div: 51322.0980\n",
            "Validation loss decreased (10246.509973 --> 10210.913245).  Saving model ...\n",
            "Epoch: 61 \tTraining Loss: 8995.5691 \tTraining Accuracy: 0.9793 \tValidation Loss: 10134.8052 \tValidation Accuracy: 0.9749 \ttrain_kl_div: 50688.0003\n",
            "Validation loss decreased (10210.913245 --> 10134.805151).  Saving model ...\n",
            "Epoch: 62 \tTraining Loss: 8847.5860 \tTraining Accuracy: 0.9799 \tValidation Loss: 10206.4995 \tValidation Accuracy: 0.9734 \ttrain_kl_div: 50188.0689\n",
            "Epoch: 63 \tTraining Loss: 8796.5813 \tTraining Accuracy: 0.9800 \tValidation Loss: 10487.4794 \tValidation Accuracy: 0.9734 \ttrain_kl_div: 49824.4964\n",
            "Epoch: 64 \tTraining Loss: 8672.0949 \tTraining Accuracy: 0.9807 \tValidation Loss: 10689.7404 \tValidation Accuracy: 0.9728 \ttrain_kl_div: 49292.1559\n",
            "Epoch: 65 \tTraining Loss: 8766.6265 \tTraining Accuracy: 0.9791 \tValidation Loss: 10486.5826 \tValidation Accuracy: 0.9743 \ttrain_kl_div: 49156.9541\n",
            "Epoch: 66 \tTraining Loss: 8610.3837 \tTraining Accuracy: 0.9799 \tValidation Loss: 10177.9202 \tValidation Accuracy: 0.9722 \ttrain_kl_div: 48705.2351\n",
            "Epoch: 67 \tTraining Loss: 8529.0499 \tTraining Accuracy: 0.9801 \tValidation Loss: 9995.2262 \tValidation Accuracy: 0.9746 \ttrain_kl_div: 48205.8039\n",
            "Validation loss decreased (10134.805151 --> 9995.226245).  Saving model ...\n",
            "Epoch: 68 \tTraining Loss: 8457.8674 \tTraining Accuracy: 0.9804 \tValidation Loss: 10375.6471 \tValidation Accuracy: 0.9724 \ttrain_kl_div: 47962.0983\n",
            "Epoch: 69 \tTraining Loss: 8527.3933 \tTraining Accuracy: 0.9803 \tValidation Loss: 9998.2888 \tValidation Accuracy: 0.9757 \ttrain_kl_div: 47838.0619\n",
            "Epoch: 70 \tTraining Loss: 8429.1790 \tTraining Accuracy: 0.9808 \tValidation Loss: 9802.2007 \tValidation Accuracy: 0.9748 \ttrain_kl_div: 47707.7253\n",
            "Validation loss decreased (9995.226245 --> 9802.200745).  Saving model ...\n",
            "Epoch: 71 \tTraining Loss: 8342.1556 \tTraining Accuracy: 0.9806 \tValidation Loss: 10210.9192 \tValidation Accuracy: 0.9735 \ttrain_kl_div: 47208.8207\n",
            "Epoch: 72 \tTraining Loss: 8478.2721 \tTraining Accuracy: 0.9799 \tValidation Loss: 10752.0033 \tValidation Accuracy: 0.9705 \ttrain_kl_div: 47236.3839\n",
            "Epoch: 73 \tTraining Loss: 8179.0772 \tTraining Accuracy: 0.9817 \tValidation Loss: 9862.0077 \tValidation Accuracy: 0.9739 \ttrain_kl_div: 46818.4877\n",
            "Epoch: 74 \tTraining Loss: 8500.3380 \tTraining Accuracy: 0.9797 \tValidation Loss: 9849.6067 \tValidation Accuracy: 0.9748 \ttrain_kl_div: 46500.2781\n",
            "Epoch: 75 \tTraining Loss: 8118.3638 \tTraining Accuracy: 0.9816 \tValidation Loss: 10127.1043 \tValidation Accuracy: 0.9746 \ttrain_kl_div: 46142.1570\n",
            "Epoch: 76 \tTraining Loss: 8195.4200 \tTraining Accuracy: 0.9808 \tValidation Loss: 9521.1577 \tValidation Accuracy: 0.9756 \ttrain_kl_div: 46094.2522\n",
            "Validation loss decreased (9802.200745 --> 9521.157739).  Saving model ...\n",
            "Epoch: 77 \tTraining Loss: 8134.3516 \tTraining Accuracy: 0.9812 \tValidation Loss: 9786.3246 \tValidation Accuracy: 0.9743 \ttrain_kl_div: 45834.7809\n",
            "Epoch: 78 \tTraining Loss: 8072.6028 \tTraining Accuracy: 0.9812 \tValidation Loss: 9638.2302 \tValidation Accuracy: 0.9751 \ttrain_kl_div: 45671.4700\n",
            "Epoch: 79 \tTraining Loss: 8002.7129 \tTraining Accuracy: 0.9811 \tValidation Loss: 9868.9671 \tValidation Accuracy: 0.9741 \ttrain_kl_div: 45343.7698\n",
            "Epoch: 80 \tTraining Loss: 8044.8437 \tTraining Accuracy: 0.9813 \tValidation Loss: 9628.2898 \tValidation Accuracy: 0.9757 \ttrain_kl_div: 45016.3798\n",
            "Epoch: 81 \tTraining Loss: 7975.6936 \tTraining Accuracy: 0.9807 \tValidation Loss: 10005.9190 \tValidation Accuracy: 0.9751 \ttrain_kl_div: 44759.6808\n",
            "Epoch: 82 \tTraining Loss: 7899.3817 \tTraining Accuracy: 0.9816 \tValidation Loss: 9183.6687 \tValidation Accuracy: 0.9749 \ttrain_kl_div: 44699.2241\n",
            "Validation loss decreased (9521.157739 --> 9183.668726).  Saving model ...\n",
            "Epoch: 83 \tTraining Loss: 7836.8498 \tTraining Accuracy: 0.9820 \tValidation Loss: 9681.0649 \tValidation Accuracy: 0.9746 \ttrain_kl_div: 44423.7299\n",
            "Epoch: 84 \tTraining Loss: 7951.8478 \tTraining Accuracy: 0.9811 \tValidation Loss: 9733.2622 \tValidation Accuracy: 0.9736 \ttrain_kl_div: 44484.8749\n",
            "Epoch: 85 \tTraining Loss: 7938.1131 \tTraining Accuracy: 0.9812 \tValidation Loss: 9922.3422 \tValidation Accuracy: 0.9754 \ttrain_kl_div: 44492.1267\n",
            "Epoch: 86 \tTraining Loss: 8043.2558 \tTraining Accuracy: 0.9810 \tValidation Loss: 10073.5357 \tValidation Accuracy: 0.9730 \ttrain_kl_div: 44549.9164\n",
            "Epoch: 87 \tTraining Loss: 7685.2697 \tTraining Accuracy: 0.9826 \tValidation Loss: 10108.2889 \tValidation Accuracy: 0.9727 \ttrain_kl_div: 44167.3186\n",
            "Epoch: 88 \tTraining Loss: 7779.8058 \tTraining Accuracy: 0.9817 \tValidation Loss: 9455.7232 \tValidation Accuracy: 0.9756 \ttrain_kl_div: 43853.5485\n",
            "Epoch    90: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch: 89 \tTraining Loss: 7941.0196 \tTraining Accuracy: 0.9811 \tValidation Loss: 9748.3183 \tValidation Accuracy: 0.9753 \ttrain_kl_div: 43956.4906\n",
            "Epoch: 90 \tTraining Loss: 7325.5570 \tTraining Accuracy: 0.9837 \tValidation Loss: 9224.8277 \tValidation Accuracy: 0.9762 \ttrain_kl_div: 43928.2798\n",
            "Epoch: 91 \tTraining Loss: 7136.1155 \tTraining Accuracy: 0.9848 \tValidation Loss: 8926.6577 \tValidation Accuracy: 0.9788 \ttrain_kl_div: 43460.1778\n",
            "Validation loss decreased (9183.668726 --> 8926.657739).  Saving model ...\n",
            "Epoch: 92 \tTraining Loss: 7140.9130 \tTraining Accuracy: 0.9847 \tValidation Loss: 9720.5944 \tValidation Accuracy: 0.9759 \ttrain_kl_div: 43019.4660\n",
            "Epoch: 93 \tTraining Loss: 6974.9449 \tTraining Accuracy: 0.9855 \tValidation Loss: 8881.3394 \tValidation Accuracy: 0.9784 \ttrain_kl_div: 42609.1353\n",
            "Validation loss decreased (8926.657739 --> 8881.339355).  Saving model ...\n",
            "Epoch: 94 \tTraining Loss: 7035.2284 \tTraining Accuracy: 0.9850 \tValidation Loss: 8857.1854 \tValidation Accuracy: 0.9779 \ttrain_kl_div: 42224.5897\n",
            "Validation loss decreased (8881.339355 --> 8857.185437).  Saving model ...\n",
            "Epoch: 95 \tTraining Loss: 6864.4232 \tTraining Accuracy: 0.9861 \tValidation Loss: 9034.5932 \tValidation Accuracy: 0.9785 \ttrain_kl_div: 41850.6507\n",
            "Epoch: 96 \tTraining Loss: 6767.7286 \tTraining Accuracy: 0.9863 \tValidation Loss: 8506.0717 \tValidation Accuracy: 0.9798 \ttrain_kl_div: 41506.2771\n",
            "Validation loss decreased (8857.185437 --> 8506.071667).  Saving model ...\n",
            "Epoch: 97 \tTraining Loss: 6767.9607 \tTraining Accuracy: 0.9857 \tValidation Loss: 9063.4379 \tValidation Accuracy: 0.9766 \ttrain_kl_div: 41183.5115\n",
            "Epoch: 98 \tTraining Loss: 6819.0862 \tTraining Accuracy: 0.9852 \tValidation Loss: 8928.7818 \tValidation Accuracy: 0.9769 \ttrain_kl_div: 40898.7183\n",
            "Epoch: 99 \tTraining Loss: 6803.6990 \tTraining Accuracy: 0.9852 \tValidation Loss: 8742.6617 \tValidation Accuracy: 0.9785 \ttrain_kl_div: 40634.2620\n",
            "Epoch: 100 \tTraining Loss: 6664.8361 \tTraining Accuracy: 0.9861 \tValidation Loss: 8805.4600 \tValidation Accuracy: 0.9766 \ttrain_kl_div: 40381.7182\n",
            "Epoch: 101 \tTraining Loss: 6716.5931 \tTraining Accuracy: 0.9854 \tValidation Loss: 8983.9305 \tValidation Accuracy: 0.9773 \ttrain_kl_div: 40138.1148\n",
            "Epoch: 102 \tTraining Loss: 6654.5998 \tTraining Accuracy: 0.9857 \tValidation Loss: 9059.7820 \tValidation Accuracy: 0.9778 \ttrain_kl_div: 39921.8945\n",
            "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch: 103 \tTraining Loss: 6658.8872 \tTraining Accuracy: 0.9858 \tValidation Loss: 8536.6202 \tValidation Accuracy: 0.9785 \ttrain_kl_div: 39715.5161\n",
            "Epoch: 104 \tTraining Loss: 6545.9936 \tTraining Accuracy: 0.9862 \tValidation Loss: 8712.0874 \tValidation Accuracy: 0.9793 \ttrain_kl_div: 39608.2927\n",
            "Epoch: 105 \tTraining Loss: 6735.1726 \tTraining Accuracy: 0.9856 \tValidation Loss: 9024.6846 \tValidation Accuracy: 0.9762 \ttrain_kl_div: 39586.0137\n",
            "Epoch: 106 \tTraining Loss: 6547.0276 \tTraining Accuracy: 0.9861 \tValidation Loss: 8589.3633 \tValidation Accuracy: 0.9792 \ttrain_kl_div: 39564.2579\n",
            "Epoch: 107 \tTraining Loss: 6602.5066 \tTraining Accuracy: 0.9860 \tValidation Loss: 9130.3303 \tValidation Accuracy: 0.9773 \ttrain_kl_div: 39541.8524\n",
            "Epoch: 108 \tTraining Loss: 6649.3968 \tTraining Accuracy: 0.9853 \tValidation Loss: 8702.7104 \tValidation Accuracy: 0.9779 \ttrain_kl_div: 39519.4417\n",
            "Epoch: 109 \tTraining Loss: 6469.4653 \tTraining Accuracy: 0.9862 \tValidation Loss: 8321.9563 \tValidation Accuracy: 0.9794 \ttrain_kl_div: 39497.0422\n",
            "Validation loss decreased (8506.071667 --> 8321.956335).  Saving model ...\n",
            "Epoch: 110 \tTraining Loss: 6492.7752 \tTraining Accuracy: 0.9864 \tValidation Loss: 8892.4420 \tValidation Accuracy: 0.9772 \ttrain_kl_div: 39474.4376\n",
            "Epoch: 111 \tTraining Loss: 6532.3501 \tTraining Accuracy: 0.9859 \tValidation Loss: 8945.8568 \tValidation Accuracy: 0.9738 \ttrain_kl_div: 39451.1499\n",
            "Epoch: 112 \tTraining Loss: 6505.4593 \tTraining Accuracy: 0.9862 \tValidation Loss: 8857.0157 \tValidation Accuracy: 0.9781 \ttrain_kl_div: 39429.1223\n",
            "Epoch: 113 \tTraining Loss: 6558.0309 \tTraining Accuracy: 0.9857 \tValidation Loss: 9065.9098 \tValidation Accuracy: 0.9772 \ttrain_kl_div: 39406.2522\n",
            "Epoch: 114 \tTraining Loss: 6526.0005 \tTraining Accuracy: 0.9860 \tValidation Loss: 8995.9700 \tValidation Accuracy: 0.9774 \ttrain_kl_div: 39383.6627\n",
            "Epoch: 115 \tTraining Loss: 6648.1699 \tTraining Accuracy: 0.9855 \tValidation Loss: 8690.4418 \tValidation Accuracy: 0.9767 \ttrain_kl_div: 39362.7890\n",
            "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch: 116 \tTraining Loss: 6484.7807 \tTraining Accuracy: 0.9864 \tValidation Loss: 8478.9184 \tValidation Accuracy: 0.9791 \ttrain_kl_div: 39340.9680\n",
            "Epoch: 117 \tTraining Loss: 6588.0444 \tTraining Accuracy: 0.9856 \tValidation Loss: 9045.7541 \tValidation Accuracy: 0.9780 \ttrain_kl_div: 39327.4364\n",
            "Epoch: 118 \tTraining Loss: 6525.5844 \tTraining Accuracy: 0.9858 \tValidation Loss: 8881.6858 \tValidation Accuracy: 0.9773 \ttrain_kl_div: 39325.3220\n",
            "Epoch: 119 \tTraining Loss: 6469.1899 \tTraining Accuracy: 0.9862 \tValidation Loss: 8890.4231 \tValidation Accuracy: 0.9773 \ttrain_kl_div: 39323.1906\n",
            "Epoch: 120 \tTraining Loss: 6380.7806 \tTraining Accuracy: 0.9864 \tValidation Loss: 8586.6285 \tValidation Accuracy: 0.9785 \ttrain_kl_div: 39320.9897\n",
            "Epoch: 121 \tTraining Loss: 6583.0288 \tTraining Accuracy: 0.9861 \tValidation Loss: 9185.9255 \tValidation Accuracy: 0.9760 \ttrain_kl_div: 39318.7359\n",
            "Epoch: 122 \tTraining Loss: 6508.2575 \tTraining Accuracy: 0.9862 \tValidation Loss: 8987.6349 \tValidation Accuracy: 0.9769 \ttrain_kl_div: 39316.5508\n",
            "Epoch   124: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch: 123 \tTraining Loss: 6365.3142 \tTraining Accuracy: 0.9866 \tValidation Loss: 8965.8990 \tValidation Accuracy: 0.9765 \ttrain_kl_div: 39314.4049\n",
            "Epoch: 124 \tTraining Loss: 6677.9647 \tTraining Accuracy: 0.9853 \tValidation Loss: 8506.4842 \tValidation Accuracy: 0.9784 \ttrain_kl_div: 39313.2223\n",
            "Epoch: 125 \tTraining Loss: 6498.0810 \tTraining Accuracy: 0.9860 \tValidation Loss: 9095.0980 \tValidation Accuracy: 0.9764 \ttrain_kl_div: 39313.0941\n",
            "Epoch: 126 \tTraining Loss: 6484.3405 \tTraining Accuracy: 0.9861 \tValidation Loss: 9092.7915 \tValidation Accuracy: 0.9770 \ttrain_kl_div: 39312.9102\n",
            "Epoch: 127 \tTraining Loss: 6509.6345 \tTraining Accuracy: 0.9861 \tValidation Loss: 9077.1722 \tValidation Accuracy: 0.9777 \ttrain_kl_div: 39312.7366\n",
            "Epoch: 128 \tTraining Loss: 6441.3803 \tTraining Accuracy: 0.9863 \tValidation Loss: 8789.6875 \tValidation Accuracy: 0.9769 \ttrain_kl_div: 39312.5830\n",
            "Epoch: 129 \tTraining Loss: 6489.4541 \tTraining Accuracy: 0.9859 \tValidation Loss: 8994.7112 \tValidation Accuracy: 0.9764 \ttrain_kl_div: 39312.4102\n",
            "Epoch   131: reducing learning rate of group 0 to 1.0000e-08.\n",
            "Epoch: 130 \tTraining Loss: 6572.3910 \tTraining Accuracy: 0.9859 \tValidation Loss: 8971.8016 \tValidation Accuracy: 0.9788 \ttrain_kl_div: 39312.2319\n",
            "Epoch: 131 \tTraining Loss: 6508.6605 \tTraining Accuracy: 0.9866 \tValidation Loss: 9055.4454 \tValidation Accuracy: 0.9763 \ttrain_kl_div: 39312.1512\n",
            "Epoch: 132 \tTraining Loss: 6456.8816 \tTraining Accuracy: 0.9867 \tValidation Loss: 8833.2390 \tValidation Accuracy: 0.9762 \ttrain_kl_div: 39312.1393\n",
            "Epoch: 133 \tTraining Loss: 6542.8491 \tTraining Accuracy: 0.9859 \tValidation Loss: 8736.0380 \tValidation Accuracy: 0.9789 \ttrain_kl_div: 39312.1283\n",
            "Epoch: 134 \tTraining Loss: 6599.6206 \tTraining Accuracy: 0.9854 \tValidation Loss: 8660.1850 \tValidation Accuracy: 0.9779 \ttrain_kl_div: 39312.1174\n",
            "Epoch: 135 \tTraining Loss: 6475.1458 \tTraining Accuracy: 0.9865 \tValidation Loss: 9139.6548 \tValidation Accuracy: 0.9757 \ttrain_kl_div: 39312.1098\n",
            "Epoch: 136 \tTraining Loss: 6603.5907 \tTraining Accuracy: 0.9856 \tValidation Loss: 9188.4200 \tValidation Accuracy: 0.9762 \ttrain_kl_div: 39312.0999\n",
            "Epoch: 137 \tTraining Loss: 6533.2069 \tTraining Accuracy: 0.9856 \tValidation Loss: 8686.7529 \tValidation Accuracy: 0.9786 \ttrain_kl_div: 39312.0908\n",
            "Epoch: 138 \tTraining Loss: 6525.4055 \tTraining Accuracy: 0.9859 \tValidation Loss: 8655.1782 \tValidation Accuracy: 0.9772 \ttrain_kl_div: 39312.0852\n",
            "Epoch: 139 \tTraining Loss: 6499.4962 \tTraining Accuracy: 0.9865 \tValidation Loss: 8805.4256 \tValidation Accuracy: 0.9778 \ttrain_kl_div: 39312.0741\n",
            "Epoch: 140 \tTraining Loss: 6461.3819 \tTraining Accuracy: 0.9858 \tValidation Loss: 8380.1617 \tValidation Accuracy: 0.9794 \ttrain_kl_div: 39312.0671\n",
            "Epoch: 141 \tTraining Loss: 6443.7510 \tTraining Accuracy: 0.9862 \tValidation Loss: 8585.7535 \tValidation Accuracy: 0.9778 \ttrain_kl_div: 39312.0557\n",
            "Epoch: 142 \tTraining Loss: 6673.0134 \tTraining Accuracy: 0.9855 \tValidation Loss: 8559.3368 \tValidation Accuracy: 0.9791 \ttrain_kl_div: 39312.0473\n",
            "Epoch: 143 \tTraining Loss: 6461.6628 \tTraining Accuracy: 0.9861 \tValidation Loss: 8987.5074 \tValidation Accuracy: 0.9756 \ttrain_kl_div: 39312.0350\n",
            "Epoch: 144 \tTraining Loss: 6519.1231 \tTraining Accuracy: 0.9862 \tValidation Loss: 8682.8334 \tValidation Accuracy: 0.9776 \ttrain_kl_div: 39312.0237\n",
            "Epoch: 145 \tTraining Loss: 6538.0103 \tTraining Accuracy: 0.9864 \tValidation Loss: 8649.4291 \tValidation Accuracy: 0.9784 \ttrain_kl_div: 39312.0135\n",
            "Epoch: 146 \tTraining Loss: 6513.0004 \tTraining Accuracy: 0.9860 \tValidation Loss: 8745.8533 \tValidation Accuracy: 0.9765 \ttrain_kl_div: 39312.0031\n",
            "Epoch: 147 \tTraining Loss: 6601.5610 \tTraining Accuracy: 0.9859 \tValidation Loss: 8770.2870 \tValidation Accuracy: 0.9762 \ttrain_kl_div: 39311.9948\n",
            "Epoch: 148 \tTraining Loss: 6512.3544 \tTraining Accuracy: 0.9857 \tValidation Loss: 8661.2017 \tValidation Accuracy: 0.9777 \ttrain_kl_div: 39311.9870\n",
            "Epoch: 149 \tTraining Loss: 6611.8988 \tTraining Accuracy: 0.9849 \tValidation Loss: 9199.2472 \tValidation Accuracy: 0.9757 \ttrain_kl_div: 39311.9761\n",
            "Epoch: 150 \tTraining Loss: 6539.6501 \tTraining Accuracy: 0.9863 \tValidation Loss: 8780.3337 \tValidation Accuracy: 0.9775 \ttrain_kl_div: 39311.9664\n",
            "Epoch: 151 \tTraining Loss: 6460.1316 \tTraining Accuracy: 0.9863 \tValidation Loss: 8590.5958 \tValidation Accuracy: 0.9772 \ttrain_kl_div: 39311.9560\n",
            "Epoch: 152 \tTraining Loss: 6518.2343 \tTraining Accuracy: 0.9859 \tValidation Loss: 8912.2529 \tValidation Accuracy: 0.9773 \ttrain_kl_div: 39311.9444\n",
            "Epoch: 153 \tTraining Loss: 6503.5873 \tTraining Accuracy: 0.9861 \tValidation Loss: 8798.3776 \tValidation Accuracy: 0.9769 \ttrain_kl_div: 39311.9357\n",
            "Epoch: 154 \tTraining Loss: 6431.2195 \tTraining Accuracy: 0.9869 \tValidation Loss: 9111.1746 \tValidation Accuracy: 0.9773 \ttrain_kl_div: 39311.9256\n",
            "Epoch: 155 \tTraining Loss: 6554.0923 \tTraining Accuracy: 0.9857 \tValidation Loss: 8596.0621 \tValidation Accuracy: 0.9787 \ttrain_kl_div: 39311.9176\n",
            "Epoch: 156 \tTraining Loss: 6541.2059 \tTraining Accuracy: 0.9861 \tValidation Loss: 8799.6060 \tValidation Accuracy: 0.9781 \ttrain_kl_div: 39311.9066\n",
            "Epoch: 157 \tTraining Loss: 6531.1937 \tTraining Accuracy: 0.9858 \tValidation Loss: 8837.9443 \tValidation Accuracy: 0.9787 \ttrain_kl_div: 39311.8962\n",
            "Epoch: 158 \tTraining Loss: 6522.4832 \tTraining Accuracy: 0.9864 \tValidation Loss: 8695.0681 \tValidation Accuracy: 0.9770 \ttrain_kl_div: 39311.8889\n",
            "Epoch: 159 \tTraining Loss: 6518.4711 \tTraining Accuracy: 0.9858 \tValidation Loss: 8689.5648 \tValidation Accuracy: 0.9771 \ttrain_kl_div: 39311.8790\n",
            "Epoch: 160 \tTraining Loss: 6649.9841 \tTraining Accuracy: 0.9852 \tValidation Loss: 8831.1732 \tValidation Accuracy: 0.9767 \ttrain_kl_div: 39311.8664\n",
            "Epoch: 161 \tTraining Loss: 6535.1709 \tTraining Accuracy: 0.9860 \tValidation Loss: 9018.3398 \tValidation Accuracy: 0.9763 \ttrain_kl_div: 39311.8576\n",
            "Epoch: 162 \tTraining Loss: 6422.9964 \tTraining Accuracy: 0.9861 \tValidation Loss: 9053.6452 \tValidation Accuracy: 0.9771 \ttrain_kl_div: 39311.8448\n",
            "Epoch: 163 \tTraining Loss: 6474.0697 \tTraining Accuracy: 0.9864 \tValidation Loss: 8861.1737 \tValidation Accuracy: 0.9770 \ttrain_kl_div: 39311.8332\n",
            "Epoch: 164 \tTraining Loss: 6593.9486 \tTraining Accuracy: 0.9852 \tValidation Loss: 8606.3475 \tValidation Accuracy: 0.9775 \ttrain_kl_div: 39311.8267\n",
            "Epoch: 165 \tTraining Loss: 6535.6532 \tTraining Accuracy: 0.9864 \tValidation Loss: 8691.2748 \tValidation Accuracy: 0.9765 \ttrain_kl_div: 39311.8194\n",
            "Epoch: 166 \tTraining Loss: 6523.6547 \tTraining Accuracy: 0.9857 \tValidation Loss: 8746.6788 \tValidation Accuracy: 0.9778 \ttrain_kl_div: 39311.8107\n",
            "Epoch: 167 \tTraining Loss: 6489.5034 \tTraining Accuracy: 0.9863 \tValidation Loss: 8797.3926 \tValidation Accuracy: 0.9775 \ttrain_kl_div: 39311.8014\n",
            "Epoch: 168 \tTraining Loss: 6589.0797 \tTraining Accuracy: 0.9858 \tValidation Loss: 8917.9390 \tValidation Accuracy: 0.9776 \ttrain_kl_div: 39311.7920\n",
            "Epoch: 169 \tTraining Loss: 6553.0541 \tTraining Accuracy: 0.9858 \tValidation Loss: 8804.6442 \tValidation Accuracy: 0.9777 \ttrain_kl_div: 39311.7811\n",
            "Epoch: 170 \tTraining Loss: 6379.2131 \tTraining Accuracy: 0.9870 \tValidation Loss: 8775.9930 \tValidation Accuracy: 0.9765 \ttrain_kl_div: 39311.7711\n",
            "Epoch: 171 \tTraining Loss: 6581.3318 \tTraining Accuracy: 0.9863 \tValidation Loss: 8902.8937 \tValidation Accuracy: 0.9771 \ttrain_kl_div: 39311.7609\n",
            "Epoch: 172 \tTraining Loss: 6569.1633 \tTraining Accuracy: 0.9862 \tValidation Loss: 8528.5533 \tValidation Accuracy: 0.9779 \ttrain_kl_div: 39311.7488\n",
            "Epoch: 173 \tTraining Loss: 6553.7168 \tTraining Accuracy: 0.9858 \tValidation Loss: 8823.2634 \tValidation Accuracy: 0.9774 \ttrain_kl_div: 39311.7366\n",
            "Epoch: 174 \tTraining Loss: 6489.9678 \tTraining Accuracy: 0.9858 \tValidation Loss: 8764.1027 \tValidation Accuracy: 0.9762 \ttrain_kl_div: 39311.7263\n",
            "Epoch: 175 \tTraining Loss: 6521.5894 \tTraining Accuracy: 0.9860 \tValidation Loss: 9122.3989 \tValidation Accuracy: 0.9767 \ttrain_kl_div: 39311.7181\n",
            "Epoch: 176 \tTraining Loss: 6592.4150 \tTraining Accuracy: 0.9860 \tValidation Loss: 8409.5271 \tValidation Accuracy: 0.9777 \ttrain_kl_div: 39311.7070\n",
            "Epoch: 177 \tTraining Loss: 6438.8612 \tTraining Accuracy: 0.9861 \tValidation Loss: 9049.4055 \tValidation Accuracy: 0.9771 \ttrain_kl_div: 39311.6994\n",
            "Epoch: 178 \tTraining Loss: 6471.3474 \tTraining Accuracy: 0.9860 \tValidation Loss: 9094.7206 \tValidation Accuracy: 0.9770 \ttrain_kl_div: 39311.6904\n",
            "Epoch: 179 \tTraining Loss: 6494.0358 \tTraining Accuracy: 0.9862 \tValidation Loss: 8764.3968 \tValidation Accuracy: 0.9779 \ttrain_kl_div: 39311.6807\n",
            "Epoch: 180 \tTraining Loss: 6555.2247 \tTraining Accuracy: 0.9861 \tValidation Loss: 8700.2290 \tValidation Accuracy: 0.9778 \ttrain_kl_div: 39311.6706\n",
            "Epoch: 181 \tTraining Loss: 6464.2315 \tTraining Accuracy: 0.9861 \tValidation Loss: 9054.5883 \tValidation Accuracy: 0.9777 \ttrain_kl_div: 39311.6603\n",
            "Epoch: 182 \tTraining Loss: 6547.5519 \tTraining Accuracy: 0.9860 \tValidation Loss: 8702.4061 \tValidation Accuracy: 0.9777 \ttrain_kl_div: 39311.6552\n",
            "Epoch: 183 \tTraining Loss: 6604.5302 \tTraining Accuracy: 0.9857 \tValidation Loss: 8848.9680 \tValidation Accuracy: 0.9777 \ttrain_kl_div: 39311.6452\n",
            "Epoch: 184 \tTraining Loss: 6587.1729 \tTraining Accuracy: 0.9853 \tValidation Loss: 8851.8470 \tValidation Accuracy: 0.9780 \ttrain_kl_div: 39311.6342\n",
            "Epoch: 185 \tTraining Loss: 6480.9040 \tTraining Accuracy: 0.9857 \tValidation Loss: 8719.3449 \tValidation Accuracy: 0.9785 \ttrain_kl_div: 39311.6267\n",
            "Epoch: 186 \tTraining Loss: 6545.1579 \tTraining Accuracy: 0.9855 \tValidation Loss: 8665.7839 \tValidation Accuracy: 0.9787 \ttrain_kl_div: 39311.6197\n",
            "Epoch: 187 \tTraining Loss: 6546.3119 \tTraining Accuracy: 0.9854 \tValidation Loss: 9214.5476 \tValidation Accuracy: 0.9761 \ttrain_kl_div: 39311.6109\n",
            "Epoch: 188 \tTraining Loss: 6498.1555 \tTraining Accuracy: 0.9859 \tValidation Loss: 8532.4441 \tValidation Accuracy: 0.9783 \ttrain_kl_div: 39311.6008\n",
            "Epoch: 189 \tTraining Loss: 6564.6812 \tTraining Accuracy: 0.9855 \tValidation Loss: 8975.9184 \tValidation Accuracy: 0.9772 \ttrain_kl_div: 39311.5918\n",
            "Epoch: 190 \tTraining Loss: 6599.3050 \tTraining Accuracy: 0.9849 \tValidation Loss: 8468.3502 \tValidation Accuracy: 0.9785 \ttrain_kl_div: 39311.5828\n",
            "Epoch: 191 \tTraining Loss: 6489.2597 \tTraining Accuracy: 0.9859 \tValidation Loss: 8532.5169 \tValidation Accuracy: 0.9778 \ttrain_kl_div: 39311.5736\n",
            "Epoch: 192 \tTraining Loss: 6527.0756 \tTraining Accuracy: 0.9860 \tValidation Loss: 8763.9694 \tValidation Accuracy: 0.9789 \ttrain_kl_div: 39311.5661\n",
            "Epoch: 193 \tTraining Loss: 6417.1519 \tTraining Accuracy: 0.9865 \tValidation Loss: 8501.4080 \tValidation Accuracy: 0.9780 \ttrain_kl_div: 39311.5562\n",
            "Epoch: 194 \tTraining Loss: 6495.3555 \tTraining Accuracy: 0.9863 \tValidation Loss: 8753.3432 \tValidation Accuracy: 0.9770 \ttrain_kl_div: 39311.5444\n",
            "Epoch: 195 \tTraining Loss: 6582.7047 \tTraining Accuracy: 0.9864 \tValidation Loss: 8577.3524 \tValidation Accuracy: 0.9778 \ttrain_kl_div: 39311.5375\n",
            "Epoch: 196 \tTraining Loss: 6644.1479 \tTraining Accuracy: 0.9853 \tValidation Loss: 8758.3681 \tValidation Accuracy: 0.9777 \ttrain_kl_div: 39311.5268\n",
            "Epoch: 197 \tTraining Loss: 6484.3659 \tTraining Accuracy: 0.9860 \tValidation Loss: 8255.0934 \tValidation Accuracy: 0.9791 \ttrain_kl_div: 39311.5181\n",
            "Validation loss decreased (8321.956335 --> 8255.093427).  Saving model ...\n",
            "Epoch: 198 \tTraining Loss: 6560.4679 \tTraining Accuracy: 0.9856 \tValidation Loss: 8748.2927 \tValidation Accuracy: 0.9777 \ttrain_kl_div: 39311.5086\n",
            "Epoch: 199 \tTraining Loss: 6551.0886 \tTraining Accuracy: 0.9860 \tValidation Loss: 8638.2305 \tValidation Accuracy: 0.9786 \ttrain_kl_div: 39311.5007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BMoCxAYVaPW"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orLiIvH6YuH-"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bClL78cKWGf-",
        "outputId": "fe7c0c58-0d0a-4097-b3b9-3c4ab561ba23"
      },
      "source": [
        "from google.colab import drive\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Colab Notebooks/'\n",
        "PATH = 'gdrive/MyDrive/Colab Notebooks/Project_StatML_Module2/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5VSkHHSWteR"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OISnPOUX0IK",
        "outputId": "b76e07e5-d4a9-4a27-d0b9-5233fd958602"
      },
      "source": [
        "%cd gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'gdrive'\n",
            "/content/BayesianCNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08HIXGwuW-E7"
      },
      "source": [
        "with open(PATH + \"LeNET_ELBO_evolution.pickle\", 'wb') as f:\n",
        "    pickle.dump(ELBO, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INOYI9S5Ysxo"
      },
      "source": [
        "with open(PATH + \"LeNET_train_acc_evolution.pickle\", 'wb') as f:\n",
        "    pickle.dump(train_acc, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXRCHdutYxk5"
      },
      "source": [
        "with open(PATH + \"LeNET_test_acc_evolution.pickle\", 'wb') as f:\n",
        "    pickle.dump(test_acc, f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}