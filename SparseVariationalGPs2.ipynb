{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import kmeans2\n",
    "from pyro.infer import MCMC, NUTS, Predictive, SVI, TraceMeanField_ELBO\n",
    "import pyro\n",
    "import pyro.contrib.gp as gp\n",
    "from pyro.contrib.examples.util import get_data_directory, get_data_loader\n",
    "import pyro.distributions as dist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading data\n",
      "download complete.\n",
      "downloading data\n",
      "download complete.\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_data_loader(dataset_name='MNIST',\n",
    "                               data_dir='~/.data',\n",
    "                               batch_size=1000,\n",
    "                               is_training_set=True,\n",
    "                               shuffle=True)\n",
    "test_loader = get_data_loader(dataset_name='MNIST',\n",
    "                              data_dir='~/.data',\n",
    "                              batch_size=1000,\n",
    "                              is_training_set=False,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = train_loader.dataset.data.float()/126\n",
    "y = train_loader.dataset.targets\n",
    "class_names = np.array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "\n",
    "n_rows, n_cols = 3, 5\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 8))\n",
    "inx = np.random.choice(X.shape[0], n_rows*n_cols, replace=False)\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.1)\n",
    "\n",
    "for n, (image, label) in enumerate(zip(X[inx], y[inx])):\n",
    "    row = n // n_cols\n",
    "    col = n % n_cols\n",
    "    axes[row, col].imshow(image, cmap='binary')\n",
    "    axes[row, col].get_xaxis().set_visible(False)\n",
    "    axes[row, col].get_yaxis().set_visible(False)\n",
    "    axes[row, col].text(10., -2.5, f'{class_names[label]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_loader.dataset.data.reshape(-1, 784).float() / 255\n",
    "y = train_loader.dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 3.0388e-19,  2.2204e-16,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-7.5503e-20, -4.5103e-17,  3.1225e-17,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 5.7568e-19, -2.7756e-17, -2.0817e-16,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        ...,\n",
       "        [ 2.9082e-18,  1.8041e-16, -3.0531e-16,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-2.2345e-18, -1.0408e-16,  1.2490e-16,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 2.3574e-18,  3.4694e-17,  4.8572e-17,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LinearT(nn.Module):\n",
    "    \"\"\"Linear transform and transpose\"\"\"\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(dim_in, dim_out, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x).t()\n",
    "\n",
    "# computes the weight for mean function of the first layer;\n",
    "# it is PCA of X (from 784D to 30D).\n",
    "_, _, V = np.linalg.svd(X.numpy(), full_matrices=False)\n",
    "W = torch.from_numpy(V[:30, :])\n",
    "\n",
    "mean_fn = LinearT(784, 30)\n",
    "mean_fn.linear.weight.data = W\n",
    "mean_fn.linear.weight.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepGP(pyro.nn.PyroModule):\n",
    "    def __init__(self, X, y, Xu, mean_fn):\n",
    "        super(DeepGP, self).__init__()\n",
    "        self.layer1 = gp.models.VariationalSparseGP(\n",
    "            X,\n",
    "            None,\n",
    "            gp.kernels.RBF(784, variance=torch.tensor(2.), lengthscale=torch.tensor(2.)),\n",
    "            Xu=Xu,\n",
    "            likelihood=None,\n",
    "            mean_function=mean_fn,\n",
    "            latent_shape=torch.Size([30]))\n",
    "        # make sure that the input for next layer is batch_size x 30\n",
    "        h = mean_fn(X).t()\n",
    "        hu = mean_fn(Xu).t()\n",
    "        self.layer2 = gp.models.VariationalSparseGP(\n",
    "            h,\n",
    "            y,\n",
    "            gp.kernels.RBF(30, variance=torch.tensor(2.), lengthscale=torch.tensor(2.)),\n",
    "            Xu=hu,\n",
    "            likelihood=gp.likelihoods.MultiClass(num_classes=10),\n",
    "            latent_shape=torch.Size([10]))\n",
    "\n",
    "    def model(self, X, y):\n",
    "        self.layer1.set_data(X, None)\n",
    "        h_loc, h_var = self.layer1.model()\n",
    "        # approximate with a Monte Carlo sample (formula 15 of [1])\n",
    "        h = dist.Normal(h_loc, h_var.sqrt())()\n",
    "        self.layer2.set_data(h.t(), y)\n",
    "        self.layer2.model()\n",
    "\n",
    "    def guide(self, X, y):\n",
    "        self.layer1.guide()\n",
    "        self.layer2.guide()\n",
    "\n",
    "    # make prediction\n",
    "    def forward(self, X_new):\n",
    "        # because prediction is stochastic (due to Monte Carlo sample of hidden layer),\n",
    "        # we make 100 prediction and take the most common one (as in [4])\n",
    "        pred = []\n",
    "        for _ in range(100):\n",
    "            h_loc, h_var = self.layer1(X_new)\n",
    "            h = dist.Normal(h_loc, h_var.sqrt())()\n",
    "            f_loc, f_var = self.layer2(h.t())\n",
    "            pred.append(f_loc.argmax(dim=0))\n",
    "        return torch.stack(pred).mode(dim=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xu = torch.from_numpy(kmeans2(X.numpy(), 100, minit='points')[0])\n",
    "deepgp = DeepGP(X, y, Xu, mean_fn)\n",
    "deepgp.layer1.u_scale_tril = deepgp.layer1.u_scale_tril * 1e-5\n",
    "#deepgp.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(deepgp.parameters(), lr=0.01)\n",
    "loss_fn = TraceMeanField_ELBO().differentiable_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, gpmodule, optimizer, loss_fn, epoch):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data, target\n",
    "        data = data.reshape(-1, 784)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(gpmodule.model, gpmodule.guide, data, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        idx = batch_idx + 1\n",
    "        if idx % 10 == 0:\n",
    "            print(\"Train Epoch: {:2d} [{:5d}/{} ({:2.0f}%)]\\tLoss: {:.6f}\"\n",
    "                  .format(epoch, idx * len(data), len(train_loader.dataset),\n",
    "                          100. * idx / len(train_loader), loss))\n",
    "\n",
    "def test(test_loader, gpmodule):\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data, target\n",
    "        data = data.reshape(-1, 784)\n",
    "        pred = gpmodule(data)\n",
    "        # compare prediction and target to count accuaracy\n",
    "        correct += pred.eq(target).long().cpu().sum().item()\n",
    "\n",
    "    print(\"\\nTest set: Accuracy: {}/{} ({:.2f}%)\\n\"\n",
    "          .format(correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  0 [10000/60000 (17%)]\tLoss: 215304.953125\n",
      "Train Epoch:  0 [20000/60000 (33%)]\tLoss: 204943.156250\n",
      "Train Epoch:  0 [30000/60000 (50%)]\tLoss: 201406.531250\n",
      "Train Epoch:  0 [40000/60000 (67%)]\tLoss: 195478.687500\n",
      "Train Epoch:  0 [50000/60000 (83%)]\tLoss: 177693.046875\n",
      "Train Epoch:  0 [60000/60000 (100%)]\tLoss: 145928.546875\n",
      "\n",
      "Test set: Accuracy: 8420/10000 (84.20%)\n",
      "\n",
      "Train Epoch:  1 [10000/60000 (17%)]\tLoss: 101692.187500\n",
      "Train Epoch:  1 [20000/60000 (33%)]\tLoss: 69872.468750\n",
      "Train Epoch:  1 [30000/60000 (50%)]\tLoss: 56267.832031\n",
      "Train Epoch:  1 [40000/60000 (67%)]\tLoss: 54678.117188\n",
      "Train Epoch:  1 [50000/60000 (83%)]\tLoss: 51300.453125\n",
      "Train Epoch:  1 [60000/60000 (100%)]\tLoss: 51296.593750\n",
      "\n",
      "Test set: Accuracy: 9323/10000 (93.23%)\n",
      "\n",
      "Train Epoch:  2 [10000/60000 (17%)]\tLoss: 49436.828125\n",
      "Train Epoch:  2 [20000/60000 (33%)]\tLoss: 46289.953125\n",
      "Train Epoch:  2 [30000/60000 (50%)]\tLoss: 45350.890625\n",
      "Train Epoch:  2 [40000/60000 (67%)]\tLoss: 48365.203125\n",
      "Train Epoch:  2 [50000/60000 (83%)]\tLoss: 43027.402344\n",
      "Train Epoch:  2 [60000/60000 (100%)]\tLoss: 41857.093750\n",
      "\n",
      "Test set: Accuracy: 9471/10000 (94.71%)\n",
      "\n",
      "Train Epoch:  3 [10000/60000 (17%)]\tLoss: 41550.699219\n",
      "Train Epoch:  3 [20000/60000 (33%)]\tLoss: 41818.195312\n",
      "Train Epoch:  3 [30000/60000 (50%)]\tLoss: 43166.222656\n",
      "Train Epoch:  3 [40000/60000 (67%)]\tLoss: 40319.839844\n",
      "Train Epoch:  3 [50000/60000 (83%)]\tLoss: 41972.730469\n",
      "Train Epoch:  3 [60000/60000 (100%)]\tLoss: 40246.554688\n",
      "\n",
      "Test set: Accuracy: 9523/10000 (95.23%)\n",
      "\n",
      "Train Epoch:  4 [10000/60000 (17%)]\tLoss: 39636.539062\n",
      "Train Epoch:  4 [20000/60000 (33%)]\tLoss: 39393.675781\n",
      "Train Epoch:  4 [30000/60000 (50%)]\tLoss: 37602.886719\n",
      "Train Epoch:  4 [40000/60000 (67%)]\tLoss: 38512.164062\n",
      "Train Epoch:  4 [50000/60000 (83%)]\tLoss: 37225.425781\n",
      "Train Epoch:  4 [60000/60000 (100%)]\tLoss: 36397.890625\n",
      "\n",
      "Test set: Accuracy: 9564/10000 (95.64%)\n",
      "\n",
      "Train Epoch:  5 [10000/60000 (17%)]\tLoss: 36085.976562\n",
      "Train Epoch:  5 [20000/60000 (33%)]\tLoss: 35419.128906\n",
      "Train Epoch:  5 [30000/60000 (50%)]\tLoss: 35407.453125\n",
      "Train Epoch:  5 [40000/60000 (67%)]\tLoss: 34089.382812\n",
      "Train Epoch:  5 [50000/60000 (83%)]\tLoss: 35824.593750\n",
      "Train Epoch:  5 [60000/60000 (100%)]\tLoss: 33144.000000\n",
      "\n",
      "Test set: Accuracy: 9585/10000 (95.85%)\n",
      "\n",
      "Train Epoch:  6 [10000/60000 (17%)]\tLoss: 33357.367188\n",
      "Train Epoch:  6 [20000/60000 (33%)]\tLoss: 32972.281250\n",
      "Train Epoch:  6 [30000/60000 (50%)]\tLoss: 32522.488281\n",
      "Train Epoch:  6 [40000/60000 (67%)]\tLoss: 32424.687500\n",
      "Train Epoch:  6 [50000/60000 (83%)]\tLoss: 34165.269531\n",
      "Train Epoch:  6 [60000/60000 (100%)]\tLoss: 33354.968750\n",
      "\n",
      "Test set: Accuracy: 9615/10000 (96.15%)\n",
      "\n",
      "Train Epoch:  7 [10000/60000 (17%)]\tLoss: 30502.441406\n",
      "Train Epoch:  7 [20000/60000 (33%)]\tLoss: 31031.529297\n",
      "Train Epoch:  7 [30000/60000 (50%)]\tLoss: 28613.613281\n",
      "Train Epoch:  7 [40000/60000 (67%)]\tLoss: 31168.156250\n",
      "Train Epoch:  7 [50000/60000 (83%)]\tLoss: 29786.730469\n",
      "Train Epoch:  7 [60000/60000 (100%)]\tLoss: 29785.875000\n",
      "\n",
      "Test set: Accuracy: 9613/10000 (96.13%)\n",
      "\n",
      "Train Epoch:  8 [10000/60000 (17%)]\tLoss: 27270.019531\n",
      "Train Epoch:  8 [20000/60000 (33%)]\tLoss: 27672.943359\n",
      "Train Epoch:  8 [30000/60000 (50%)]\tLoss: 26623.406250\n",
      "Train Epoch:  8 [40000/60000 (67%)]\tLoss: 27244.859375\n",
      "Train Epoch:  8 [50000/60000 (83%)]\tLoss: 25493.898438\n",
      "Train Epoch:  8 [60000/60000 (100%)]\tLoss: 26868.382812\n",
      "\n",
      "Test set: Accuracy: 9621/10000 (96.21%)\n",
      "\n",
      "Train Epoch:  9 [10000/60000 (17%)]\tLoss: 26211.277344\n",
      "Train Epoch:  9 [20000/60000 (33%)]\tLoss: 26017.375000\n",
      "Train Epoch:  9 [30000/60000 (50%)]\tLoss: 27239.671875\n",
      "Train Epoch:  9 [40000/60000 (67%)]\tLoss: 25612.005859\n",
      "Train Epoch:  9 [50000/60000 (83%)]\tLoss: 24870.066406\n",
      "Train Epoch:  9 [60000/60000 (100%)]\tLoss: 23861.355469\n",
      "\n",
      "Test set: Accuracy: 9629/10000 (96.29%)\n",
      "\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 22967.644531\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 22726.714844\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 27511.031250\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 22478.835938\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 21896.761719\n",
      "Train Epoch: 10 [60000/60000 (100%)]\tLoss: 23088.824219\n",
      "\n",
      "Test set: Accuracy: 9646/10000 (96.46%)\n",
      "\n",
      "Train Epoch: 11 [10000/60000 (17%)]\tLoss: 21327.136719\n",
      "Train Epoch: 11 [20000/60000 (33%)]\tLoss: 20351.285156\n",
      "Train Epoch: 11 [30000/60000 (50%)]\tLoss: 22000.632812\n",
      "Train Epoch: 11 [40000/60000 (67%)]\tLoss: 20139.427734\n",
      "Train Epoch: 11 [50000/60000 (83%)]\tLoss: 20710.269531\n",
      "Train Epoch: 11 [60000/60000 (100%)]\tLoss: 19249.787109\n",
      "\n",
      "Test set: Accuracy: 9642/10000 (96.42%)\n",
      "\n",
      "Train Epoch: 12 [10000/60000 (17%)]\tLoss: 20604.882812\n",
      "Train Epoch: 12 [20000/60000 (33%)]\tLoss: 18930.613281\n",
      "Train Epoch: 12 [30000/60000 (50%)]\tLoss: 19819.703125\n",
      "Train Epoch: 12 [40000/60000 (67%)]\tLoss: 19043.078125\n",
      "Train Epoch: 12 [50000/60000 (83%)]\tLoss: 20297.015625\n",
      "Train Epoch: 12 [60000/60000 (100%)]\tLoss: 17618.650391\n",
      "\n",
      "Test set: Accuracy: 9666/10000 (96.66%)\n",
      "\n",
      "Train Epoch: 13 [10000/60000 (17%)]\tLoss: 17646.015625\n",
      "Train Epoch: 13 [20000/60000 (33%)]\tLoss: 16844.177734\n",
      "Train Epoch: 13 [30000/60000 (50%)]\tLoss: 17785.195312\n",
      "Train Epoch: 13 [40000/60000 (67%)]\tLoss: 16946.318359\n",
      "Train Epoch: 13 [50000/60000 (83%)]\tLoss: 16024.724609\n",
      "Train Epoch: 13 [60000/60000 (100%)]\tLoss: 18534.550781\n",
      "\n",
      "Test set: Accuracy: 9671/10000 (96.71%)\n",
      "\n",
      "Train Epoch: 14 [10000/60000 (17%)]\tLoss: 13996.033203\n",
      "Train Epoch: 14 [20000/60000 (33%)]\tLoss: 15558.895508\n",
      "Train Epoch: 14 [30000/60000 (50%)]\tLoss: 18051.152344\n",
      "Train Epoch: 14 [40000/60000 (67%)]\tLoss: 15996.312500\n",
      "Train Epoch: 14 [50000/60000 (83%)]\tLoss: 15573.685547\n",
      "Train Epoch: 14 [60000/60000 (100%)]\tLoss: 15555.128906\n",
      "\n",
      "Test set: Accuracy: 9686/10000 (96.86%)\n",
      "\n",
      "Train Epoch: 15 [10000/60000 (17%)]\tLoss: 17408.255859\n",
      "Train Epoch: 15 [20000/60000 (33%)]\tLoss: 14778.535156\n",
      "Train Epoch: 15 [30000/60000 (50%)]\tLoss: 16889.636719\n",
      "Train Epoch: 15 [40000/60000 (67%)]\tLoss: 14615.398438\n",
      "Train Epoch: 15 [50000/60000 (83%)]\tLoss: 15265.431641\n",
      "Train Epoch: 15 [60000/60000 (100%)]\tLoss: 14053.040039\n",
      "\n",
      "Test set: Accuracy: 9703/10000 (97.03%)\n",
      "\n",
      "Train Epoch: 16 [10000/60000 (17%)]\tLoss: 16351.468750\n",
      "Train Epoch: 16 [20000/60000 (33%)]\tLoss: 15395.652344\n",
      "Train Epoch: 16 [30000/60000 (50%)]\tLoss: 13982.623047\n",
      "Train Epoch: 16 [40000/60000 (67%)]\tLoss: 16072.693359\n",
      "Train Epoch: 16 [50000/60000 (83%)]\tLoss: 15066.100586\n",
      "Train Epoch: 16 [60000/60000 (100%)]\tLoss: 13372.753906\n",
      "\n",
      "Test set: Accuracy: 9694/10000 (96.94%)\n",
      "\n",
      "Train Epoch: 17 [10000/60000 (17%)]\tLoss: 14329.423828\n",
      "Train Epoch: 17 [20000/60000 (33%)]\tLoss: 15453.166016\n",
      "Train Epoch: 17 [30000/60000 (50%)]\tLoss: 14835.336914\n",
      "Train Epoch: 17 [40000/60000 (67%)]\tLoss: 14536.529297\n",
      "Train Epoch: 17 [50000/60000 (83%)]\tLoss: 14707.187500\n",
      "Train Epoch: 17 [60000/60000 (100%)]\tLoss: 11991.744141\n",
      "\n",
      "Test set: Accuracy: 9701/10000 (97.01%)\n",
      "\n",
      "Train Epoch: 18 [10000/60000 (17%)]\tLoss: 14718.818359\n",
      "Train Epoch: 18 [20000/60000 (33%)]\tLoss: 13355.433594\n",
      "Train Epoch: 18 [30000/60000 (50%)]\tLoss: 14096.183594\n",
      "Train Epoch: 18 [40000/60000 (67%)]\tLoss: 15216.175781\n",
      "Train Epoch: 18 [50000/60000 (83%)]\tLoss: 14272.296875\n",
      "Train Epoch: 18 [60000/60000 (100%)]\tLoss: 16107.884766\n",
      "\n",
      "Test set: Accuracy: 9704/10000 (97.04%)\n",
      "\n",
      "Train Epoch: 19 [10000/60000 (17%)]\tLoss: 12922.849609\n",
      "Train Epoch: 19 [20000/60000 (33%)]\tLoss: 13239.670898\n",
      "Train Epoch: 19 [30000/60000 (50%)]\tLoss: 14796.490234\n",
      "Train Epoch: 19 [40000/60000 (67%)]\tLoss: 13332.190430\n",
      "Train Epoch: 19 [50000/60000 (83%)]\tLoss: 12650.153320\n",
      "Train Epoch: 19 [60000/60000 (100%)]\tLoss: 15274.054688\n",
      "\n",
      "Test set: Accuracy: 9711/10000 (97.11%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train(train_loader, deepgp, optimizer, loss_fn, i)\n",
    "    with torch.no_grad():\n",
    "        test(test_loader, deepgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
